{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd08a03-b30b-40c6-91e1-783b17be838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416ecfd-f49d-442e-a0c1-dbfaeb131f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a71316-421e-4e9f-b5aa-417fa3154129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir, label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label,\"complete\")\n",
    "    return image_paths,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd758f2-bd68-49fb-9aea-d952ff2dfd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeac5df-d907-4c60-99a1-aee43125326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79352d9-65b5-4dbf-bd92-f2e971fd3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8bd05a-b6c1-4f2f-badd-c66c67389fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bbbb36-c32a-40e6-9c80-bfb0f7990bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images, target_size=(48, 48)):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        # Load the image in grayscale mode\n",
    "        img = load_img(image, color_mode='grayscale', target_size=target_size)\n",
    "        \n",
    "        # Convert image to array\n",
    "        img = img_to_array(img)\n",
    "        \n",
    "        # Append the image array to features list\n",
    "        features.append(img)\n",
    "    \n",
    "    # Convert features list to a numpy array\n",
    "    features = np.array(features)\n",
    "    \n",
    "    # Ensure features have the correct shape\n",
    "    features = np.expand_dims(features, axis=-1)  # Adds the channel dimension for grayscale (48, 48, 1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95894d8-17eb-4f1c-8870-62fbbd9924c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = extract_features(train['image']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc324a00-b70e-4809-aca4-807784eb3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033dd4b0-82be-48b0-a80b-eef3cb4522d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4c660-12b9-47fa-91bf-c6fd1c813dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88efd986-e05b-4c16-8a7a-a6ec1d43feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c0c8e-9860-4891-8407-6dee0897930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48c810-838e-44fd-90c7-0070b91b9eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e463508-3b2f-4f93-938e-b713bfebe220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Input(shape=(48, 48, 1)))\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Flatten the output from convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output layer with 7 classes (for classification)\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771265f6-791e-4a37-b038-edcf711dca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x= x_train,y = y_train, batch_size = 128, epochs = 100, validation_data = (x_test,y_test)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb902e1a-3ca5-46a3-977c-cc8defd3b570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17f7da30-7ac4-4ac0-8396-93928ac6e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f43255c-47a8-485c-8aa9-b929ee2b2662",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"emotiondetector.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "142c92e4-fef2-4f6d-83e1-bf94af9713e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c27f5564-bb6a-4a19-818a-61005ec6f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image,grayscale =  True )\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea0caaec-6483-44cb-9196-d1e03814042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "def ef(image):\n",
    "    # Load the image in grayscale mode using color_mode='grayscale'\n",
    "    img = load_img(image, color_mode='grayscale', target_size=(48, 48))\n",
    "    \n",
    "    # Convert the image to an array\n",
    "    feature = img_to_array(img)\n",
    "    \n",
    "    # Reshape to add batch dimension (1, 48, 48, 1)\n",
    "    feature = feature.reshape(1, 48, 48, 1)\n",
    "    \n",
    "    # Normalize the pixel values (optional, depending on how your model was trained)\n",
    "    feature = feature / 255.0\n",
    "    \n",
    "    return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ff4ca66-4dc6-470a-9e5b-93dfd2717bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image is of sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step\n",
      "Model prediction is sad\n"
     ]
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"Original image is of sad\")\n",
    "\n",
    "# Preprocess the image\n",
    "img = ef(image)\n",
    "\n",
    "# Make a prediction\n",
    "pred = model.predict(img)\n",
    "\n",
    "# Get the predicted label\n",
    "label = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "pred_label = label[pred.argmax()]\n",
    "\n",
    "print(\"Model prediction is\", pred_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b773fd7-2c75-4d7f-aec9-6c2cb25e47a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
